{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"../1m_health_events_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------+--------+--------------------+----------+\n",
      "|           EventType|          Timestamp|Location|Severity|             Details|Is_Anomaly|\n",
      "+--------------------+-------------------+--------+--------+--------------------+----------+\n",
      "|  emergency_incident|2022-01-01 00:00:00|  Boston|    high|This is a simulat...|         0|\n",
      "|      health_mention|2022-01-01 00:01:00|   Tokyo|     low|This is a simulat...|         0|\n",
      "|      health_mention|2022-01-01 00:01:00|   Tokyo|  medium|This is a simulat...|         0|\n",
      "|         vaccination|2022-01-01 00:01:00|  Boston|  medium|This is a simulat...|         0|\n",
      "|general_health_re...|2022-01-01 00:03:00|   Tokyo|  medium|This is a simulat...|         0|\n",
      "+--------------------+-------------------+--------+--------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, month, dayofweek, hour, date_format\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Drop the Details column if it exists\n",
    "df = df.drop(\"Details\")\n",
    "\n",
    "# Split the Timestamp column into different components\n",
    "df = df.withColumn(\"Year_Month\", date_format(col(\"Timestamp\"), \"yyyy-MM\")) \\\n",
    "    .withColumn(\"Day_of_Week\", date_format(col(\"Timestamp\"), \"E\")) \\\n",
    "    .withColumn(\"Hour_of_Day\", hour(col(\"Timestamp\")))\n",
    "\n",
    "# Drop the Timestamp column\n",
    "df = df.drop(\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"EventType\", \"Location\", \"Severity\", \"Day_of_Week\", \"Year_Month\"]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"keep\") for col in categorical_cols]\n",
    "encoder = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=col+\"_encoded\") for indexer, col in zip(indexers, categorical_cols)]\n",
    "feature_cols = [\"EventType_encoded\", \"Location_encoded\", \"Severity_encoded\", \"Day_of_Week_encoded\", \"Year_Month_encoded\", \"Hour_of_Day\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=843)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Is_Anomaly\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 20:48:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/05/08 20:48:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9998702031320983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9998702199803345\n",
      "Recall =  0.9998702031320983\n",
      "F1 Score =  0.9998364601587763\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "logisticReg = LogisticRegression(featuresCol='features', labelCol='Is_Anomaly')\n",
    "pipeline_stages = indexers + encoder + [assembler, logisticReg]\n",
    "pipeline_log = Pipeline(stages=pipeline_stages)\n",
    "model_log = pipeline_log.fit(trainingData)\n",
    "predictions_log = model_log.transform(testData)\n",
    "print(f\"Accuracy = \",evaluator.setMetricName(\"accuracy\").evaluate(predictions_log))\n",
    "print(f\"Precision = \",evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions_log))\n",
    "print(f\"Recall = \",evaluator.setMetricName(\"weightedRecall\").evaluate(predictions_log))\n",
    "print(f\"F1 Score = \",evaluator.setMetricName(\"f1\").evaluate(predictions_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9998702031320983\n",
      "Precision =  0.9998702199803345\n",
      "Recall =  0.9998702031320983\n",
      "F1 Score =  0.9998364601587763\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'Is_Anomaly', maxDepth = 3)\n",
    "pipeline_stages_dt = indexers + encoder + [assembler, dtree]\n",
    "pipeline_dt = Pipeline(stages=pipeline_stages_dt)\n",
    "model_dt = pipeline_dt.fit(trainingData)\n",
    "predictions_dt = model_dt.transform(testData)\n",
    "print(f\"Accuracy = \",evaluator.setMetricName(\"accuracy\").evaluate(predictions_dt))\n",
    "print(f\"Precision = \",evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions_dt))\n",
    "print(f\"Recall = \",evaluator.setMetricName(\"weightedRecall\").evaluate(predictions_dt))\n",
    "print(f\"F1 Score = \",evaluator.setMetricName(\"f1\").evaluate(predictions_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 20:49:13 WARN MemoryStore: Not enough space to cache rdd_466_1 in memory! (computed 20.0 MiB so far)\n",
      "24/05/08 20:49:13 WARN BlockManager: Persisting block rdd_466_1 to disk instead.\n",
      "24/05/08 20:49:13 WARN MemoryStore: Not enough space to cache rdd_466_2 in memory! (computed 30.0 MiB so far)\n",
      "24/05/08 20:49:13 WARN BlockManager: Persisting block rdd_466_2 to disk instead.\n",
      "24/05/08 20:49:13 WARN MemoryStore: Not enough space to cache rdd_466_0 in memory! (computed 30.0 MiB so far)\n",
      "24/05/08 20:49:13 WARN BlockManager: Persisting block rdd_466_0 to disk instead.\n",
      "24/05/08 20:49:13 WARN MemoryStore: Not enough space to cache rdd_466_4 in memory! (computed 30.0 MiB so far)\n",
      "24/05/08 20:49:13 WARN BlockManager: Persisting block rdd_466_4 to disk instead.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9998102968853744\n",
      "Precision =  0.9996206297580206\n",
      "Recall =  0.9998102968853744\n",
      "F1 Score =  0.9997154543257329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'Is_Anomaly')\n",
    "pipeline_stages_rf = indexers + encoder + [assembler, rf]\n",
    "pipeline_rf = Pipeline(stages=pipeline_stages_rf)\n",
    "model_rf = pipeline_rf.fit(trainingData)\n",
    "predictions_rf = model_rf.transform(testData)\n",
    "print(f\"Accuracy = \",evaluator.setMetricName(\"accuracy\").evaluate(predictions_rf))\n",
    "print(f\"Precision = \",evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions_rf))\n",
    "print(f\"Recall = \",evaluator.setMetricName(\"weightedRecall\").evaluate(predictions_rf))\n",
    "print(f\"F1 Score = \",evaluator.setMetricName(\"f1\").evaluate(predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9998702031320983\n",
      "Precision =  0.9998702199803345\n",
      "Recall =  0.9998702031320983\n",
      "F1 Score =  0.9998364601587763\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='Is_Anomaly', predictionCol='prediction')\n",
    "pipeline_stages_gbt = indexers + encoder + [assembler, gbt]\n",
    "pipeline_gbt = Pipeline(stages=pipeline_stages_gbt)\n",
    "model_gbt = pipeline_gbt.fit(trainingData)\n",
    "predictions_gbt = model_gbt.transform(testData)\n",
    "print(f\"Accuracy = \",evaluator.setMetricName(\"accuracy\").evaluate(predictions_gbt))\n",
    "print(f\"Precision = \",evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions_gbt))\n",
    "print(f\"Recall = \",evaluator.setMetricName(\"weightedRecall\").evaluate(predictions_gbt))\n",
    "print(f\"F1 Score = \",evaluator.setMetricName(\"f1\").evaluate(predictions_gbt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gbt_model\"\n",
    "\n",
    "model_path = \"./gbt_model\"\n",
    "\n",
    "model_gbt.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
